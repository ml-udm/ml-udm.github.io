<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Workshop on Machine Learning and User Decision Making | ml-udm.github.io</title>
<meta name="generator" content="Jekyll v3.7.4" />
<meta property="og:title" content="Workshop on Machine Learning and User Decision Making" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="https://ml-udm.github.io/" />
<meta property="og:url" content="https://ml-udm.github.io/" />
<meta property="og:site_name" content="ml-udm.github.io" />
<script type="application/ld+json">
{"@type":"WebSite","url":"https://ml-udm.github.io/","headline":"Workshop on Machine Learning and User Decision Making","name":"ml-udm.github.io","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="/assets/css/style.css?v=1fd887da03f36fc680648dc1ab81fd840d673d54">
  </head>

<body>

<div class="container-lg px-3 my-5 markdown-body">

<h2>Title:</h2> 
  
Adaptive Experimental Design with Temporal Interference

<h2>Speaker:</h2> 
  
<a href="http://web.stanford.edu/~rjohari/">Ramesh Johari</a>, Stanford University
  
<h2>Abstract:</h2>

<p>
We consider experimental design in dynamic systems where the treatment and control can change the 
state of the system (e.g., the pricing algorithm of a ridesharing system, the matching algorithm of 
a delivery system, or the reserve price in ad auctions).  In such systems, naively applying 
classical A/B tests that randomize units to treatment or control and taking sample averages of the 
groups suffers from *temporal interference*: the application of policy A to some units affects the 
state of the system as seen by policy B on other units.
</p>

<p>
Motivated by this problem, our key innovation is to model it as one of estimating the difference of 
the steady state reward between two different policies in a Markov chain with unknown transitions 
and rewards that depend on the actions (treatment or control). We characterize the adaptive 
experimental design and estimator that are consist and efficient in this setting. For practical 
implementation, we propose alternative estimators and corresponding optimal policies, and study the 
efficiency gap of these designs.
</p>
  
<p>
Joint work with Peter Glynn and Mohammad Rasouli.
</p>

<h2></h2>  

<p>
Back to the <a href="https://ml-udm.github.io">workshop page</a>  
</p>
  
</div>
  
</body>  
  
</html>
